{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SC 500M Instructions MOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          workload  Channel  interface  1RFM-1tREFI  1RFM-2tREFI  1RFM-4tREFI  \\\n",
      "0        401.bzip2      1.0     8000.0     0.961749     0.981761     0.990550   \n",
      "1          403.gcc      1.0     8000.0     0.990611     0.996017     0.997740   \n",
      "2          429.mcf      1.0     8000.0     0.893537     0.946820     0.973584   \n",
      "3         433.milc      1.0     8000.0     0.896146     0.948166     0.974270   \n",
      "4       434.zeusmp      1.0     8000.0     0.877834     0.938773     0.969148   \n",
      "..             ...      ...        ...          ...          ...          ...   \n",
      "59         TPC (4)      1.0     8000.0     0.917320     0.958564     0.979780   \n",
      "60      Hadoop (3)      1.0     8000.0     0.914041     0.957658     0.978984   \n",
      "61  MediaBench (3)      1.0     8000.0     0.951537     0.976708     0.988594   \n",
      "62        YCSB (6)      1.0     8000.0     0.900282     0.949754     0.974778   \n",
      "63        All (57)      1.0     8000.0     0.928146     0.964548     0.982457   \n",
      "\n",
      "    2RFM-1tREFI  4RFM-1tREFI  \n",
      "0      0.919849     0.796982  \n",
      "1      0.974921     0.878667  \n",
      "2      0.792300     0.554443  \n",
      "3      0.796478     0.554024  \n",
      "4      0.755555     0.514984  \n",
      "..          ...          ...  \n",
      "59     0.835176     0.629689  \n",
      "60     0.823164     0.618828  \n",
      "61     0.899090     0.757067  \n",
      "62     0.804446     0.587190  \n",
      "63     0.852315     0.669833  \n",
      "\n",
      "[64 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "baseline_4cores_out_path = '../../prac_study/TimingChannel/SC/OriginalTiming'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"mitigation\", \"workload\", \"WS\"])\n",
    "mitigation_list = [\"Baseline\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "for mitigation in mitigation_list:\n",
    "    result_path = baseline_4cores_out_path + \"/\" + mitigation +\"/stats/\"\n",
    "    result_list = [x[:-4] for x in os.listdir(result_path) if x.endswith(\".txt\")]\n",
    "    for result_filename in result_list:\n",
    "        result_file = open(result_path + result_filename + \".txt\", \"r\")\n",
    "        Channel = int(result_filename.split(\"_\")[0])\n",
    "        interface = int(result_filename.split(\"_\")[1])\n",
    "\n",
    "        workload = \"_\".join(result_filename.split(\"_\")[2:])\n",
    "\n",
    "        ipc_0 = 0\n",
    "        cycle_0 = 0\n",
    "        num_inst_0=0\n",
    "        num_inst_1=0\n",
    "        num_inst_2=0\n",
    "        num_inst_3=0\n",
    "        num_abo=0\n",
    "        num_tREFI_period=0\n",
    "        num_tREFW_period=0\n",
    "        num_rd_reqs=0\n",
    "        num_wr_reqs=0\n",
    "        for line in result_file.readlines():\n",
    "            if (\" cycles_recorded_core_0:\" in line):\n",
    "                cycle_0 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_0\" in line):\n",
    "                num_inst_0 = int(line.split(\" \")[-1])\n",
    "            if (\" prac_num_recovery\" in line):\n",
    "                num_abo = int(line.split(\" \")[-1])\n",
    "            if (\" num_refresh_command_0\" in line):\n",
    "                num_tREFI_period = int(line.split(\" \")[-1])\n",
    "            if (\" num_refresh_window_0\" in line):\n",
    "                num_tREFW_period = int(line.split(\" \")[-1])            \n",
    "            if (\" total_num_read_requests\" in line):\n",
    "                num_rd_reqs = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_write_requests\" in line):\n",
    "                num_wr_reqs = int(line.split(\" \")[-1])\n",
    "\n",
    "        if (cycle_0 == 0):\n",
    "            continue\n",
    "        if (cycle_0 == 0 ):\n",
    "            print(\"Error: \" + result_filename)\n",
    "        ipc_0 = int(num_inst_0) / cycle_0\n",
    "        wr_reqs_ratio = float(int(num_wr_reqs)/int(num_rd_reqs + num_wr_reqs))\n",
    "\n",
    "        result_file.close()\n",
    "        # Create a new DataFrame for the new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'mitigation': [mitigation],\n",
    "            'workload': [workload],\n",
    "            'Channel': [Channel],\n",
    "            'interface': [interface],\n",
    "            'WS': [ipc_0],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "df_ws = df.pivot(index=['workload', 'Channel', 'interface'], columns=['mitigation'], values='WS').reset_index()\n",
    "df_ws[['workload', 'Channel','interface', 'Baseline']].to_csv('../stats/SC_500M_DDR5_8000_Original_Baseline.csv', index=False)\n",
    "\n",
    "for mitigation in set(mitigation_list) - set(['Baseline']):\n",
    "     df_ws[mitigation] = df_ws[mitigation] / df_ws['Baseline']\n",
    "df_ws.drop(columns=['Baseline'], inplace=True)\n",
    "\n",
    "# Define benchmark suites and their corresponding workloads\n",
    "benchmark_suites = {\n",
    "    'SPEC2K6 (23)': ['401.bzip2', '403.gcc', '429.mcf', '433.milc', '434.zeusmp', '435.gromacs', '436.cactusADM', '437.leslie3d', '444.namd', '445.gobmk', '447.dealII', '450.soplex', '456.hmmer', '458.sjeng', '459.GemsFDTD', '462.libquantum', '464.h264ref', '470.lbm', '471.omnetpp', '473.astar', '481.wrf', '482.sphinx3', '483.xalancbmk'], # SPEC2K6: 23\n",
    "    'SPEC2K17 (18)': ['500.perlbench', '502.gcc', '505.mcf', '507.cactuBSSN', '508.namd', '510.parest', '511.povray', '519.lbm', '520.omnetpp', '523.xalancbmk', '525.x264', '526.blender', '531.deepsjeng', '538.imagick', '541.leela', '544.nab', '549.fotonik3d', '557.xz'], # SPEC2K17: 18\n",
    "    'TPC (4)': ['tpcc64', 'tpch17', 'tpch2', 'tpch6'], #tpc: 4\n",
    "    # TODO: Enable Hadoop and LonestartGPU after fixing the performance shooting problem + h264_decode\n",
    "    'Hadoop (3)': ['grep_map0', 'wc_8443', 'wc_map0'], #Hadoop: 3\n",
    "    'MediaBench (3)': ['h264_encode', 'jp2_decode', 'jp2_encode'], #mediabench: 3\n",
    "    'YCSB (6)': ['ycsb_abgsave', 'ycsb_aserver', 'ycsb_bserver', 'ycsb_cserver', 'ycsb_dserver', 'ycsb_eserver'] #ycsb:6\n",
    "}\n",
    "\n",
    "#\n",
    "mitigation_list = [\"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "# Function to calculate geometric mean\n",
    "def calculate_geometric_mean(series):\n",
    "    return np.prod(series) ** (1 / len(series))\n",
    "\n",
    "# Function to calculate and add geometric means as new rows\n",
    "def add_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "\n",
    "    for Channel in df['Channel'].unique():\n",
    "        for interface in df['interface'].unique():  # Loop through unique interfaces\n",
    "            for suite_name, workloads in benchmark_suites.items():\n",
    "                suite_df = df[(df['workload'].isin(workloads)) & (df['Channel'] == Channel) & (df['interface'] == interface)]\n",
    "                if not suite_df.empty:\n",
    "                    geomeans = {}\n",
    "                    \n",
    "                    # Dynamically calculate geometric means for each mitigation\n",
    "                    for mitigation in mitigation_list:\n",
    "                        if mitigation in suite_df.columns:  # Ensure the column exists\n",
    "                            geomeans[mitigation] = calculate_geometric_mean(suite_df[mitigation])\n",
    "                    \n",
    "                    # Create a new row\n",
    "                    geomean_row = {'Channel': Channel, 'interface': interface, 'workload': suite_name, **geomeans}\n",
    "                    geomean_rows.append(geomean_row)  # Append to the list\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "# Function to add combined geometric means for all workloads in each channel and interface\n",
    "def add_all_workloads_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "    \n",
    "    for Channel in df['Channel'].unique():\n",
    "        for interface in df['interface'].unique():  # Loop through unique interfaces\n",
    "            Channel_interface_df = df[(df['Channel'] == Channel) & (df['interface'] == interface)]\n",
    "            geomean_values = {}\n",
    "\n",
    "            # Calculate geometric means for each mitigation in the list\n",
    "            for mitigation in mitigation_list:\n",
    "                if mitigation in Channel_interface_df.columns:  # Ensure the column exists\n",
    "                    geomean_values[mitigation] = calculate_geometric_mean(Channel_interface_df[mitigation])\n",
    "\n",
    "            # Create a new row for the combined results\n",
    "            geomean_row = {'Channel': Channel, 'interface': interface, 'workload': 'All (57)', **geomean_values}\n",
    "            geomean_rows.append(geomean_row)  # Append to the list\n",
    "    \n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "# Call function to calculate and merge geometric means\n",
    "geomean_df = add_geomean_rows(df_ws)\n",
    "geomean_df = add_all_workloads_geomean_rows(geomean_df)\n",
    "print(geomean_df)\n",
    "geomean_df.to_csv('./../stats/SC_500M_Timing_Based_RFM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          workload  Channel  interface  1RFM-1tREFI  1RFM-2tREFI  1RFM-4tREFI  \\\n",
      "0        401.bzip2      1.0     8000.0     0.969892     0.985358     0.992436   \n",
      "1          403.gcc      1.0     8000.0     0.996713     0.999167     0.999464   \n",
      "2          429.mcf      1.0     8000.0     0.925416     0.962599     0.981274   \n",
      "3         433.milc      1.0     8000.0     0.931943     0.965892     0.983253   \n",
      "4       434.zeusmp      1.0     8000.0     0.900488     0.949822     0.975212   \n",
      "..             ...      ...        ...          ...          ...          ...   \n",
      "59         TPC (4)      1.0     8000.0     0.936132     0.968988     0.984172   \n",
      "60      Hadoop (3)      1.0     8000.0     0.926400     0.963683     0.981986   \n",
      "61  MediaBench (3)      1.0     8000.0     0.958530     0.979662     0.990032   \n",
      "62        YCSB (6)      1.0     8000.0     0.920888     0.960317     0.980441   \n",
      "63        All (57)      1.0     8000.0     0.943388     0.972088     0.985996   \n",
      "\n",
      "    2RFM-1tREFI  4RFM-1tREFI  \n",
      "0      0.935354     0.837650  \n",
      "1      0.985811     0.898462  \n",
      "2      0.862481     0.663700  \n",
      "3      0.875807     0.673465  \n",
      "4      0.800952     0.598274  \n",
      "..          ...          ...  \n",
      "59     0.873900     0.700306  \n",
      "60     0.851099     0.680185  \n",
      "61     0.913598     0.798374  \n",
      "62     0.848262     0.663048  \n",
      "63     0.884887     0.739063  \n",
      "\n",
      "[64 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "baseline_4cores_out_path = '../../prac_study/TimingChannel/SC/PRACTiming'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"mitigation\", \"workload\", \"WS\"])\n",
    "mitigation_list = [\"Baseline\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "for mitigation in mitigation_list:\n",
    "    result_path = baseline_4cores_out_path + \"/\" + mitigation +\"/stats/\"\n",
    "    result_list = [x[:-4] for x in os.listdir(result_path) if x.endswith(\".txt\")]\n",
    "    for result_filename in result_list:\n",
    "        result_file = open(result_path + result_filename + \".txt\", \"r\")\n",
    "        Channel = int(result_filename.split(\"_\")[0])\n",
    "        interface = int(result_filename.split(\"_\")[1])\n",
    "\n",
    "        workload = \"_\".join(result_filename.split(\"_\")[2:])\n",
    "\n",
    "        ipc_0 = 0\n",
    "        cycle_0 = 0\n",
    "        num_inst_0=0\n",
    "        num_inst_1=0\n",
    "        num_inst_2=0\n",
    "        num_inst_3=0\n",
    "        num_abo=0\n",
    "        num_tREFI_period=0\n",
    "        num_tREFW_period=0\n",
    "        num_rd_reqs=0\n",
    "        num_wr_reqs=0\n",
    "        for line in result_file.readlines():\n",
    "            if (\" cycles_recorded_core_0:\" in line):\n",
    "                cycle_0 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_0\" in line):\n",
    "                num_inst_0 = int(line.split(\" \")[-1])\n",
    "            if (\" prac_num_recovery\" in line):\n",
    "                num_abo = int(line.split(\" \")[-1])\n",
    "            if (\" num_refresh_command_0\" in line):\n",
    "                num_tREFI_period = int(line.split(\" \")[-1])\n",
    "            if (\" num_refresh_window_0\" in line):\n",
    "                num_tREFW_period = int(line.split(\" \")[-1])            \n",
    "            if (\" total_num_read_requests\" in line):\n",
    "                num_rd_reqs = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_write_requests\" in line):\n",
    "                num_wr_reqs = int(line.split(\" \")[-1])\n",
    "\n",
    "        if (cycle_0 == 0):\n",
    "            continue\n",
    "        if (cycle_0 == 0 ):\n",
    "            print(\"Error: \" + result_filename)\n",
    "        ipc_0 = int(num_inst_0) / cycle_0\n",
    "        wr_reqs_ratio = float(int(num_wr_reqs)/int(num_rd_reqs + num_wr_reqs))\n",
    "\n",
    "        result_file.close()\n",
    "        # Create a new DataFrame for the new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'mitigation': [mitigation],\n",
    "            'workload': [workload],\n",
    "            'Channel': [Channel],\n",
    "            'interface': [interface],\n",
    "            'WS': [ipc_0],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df_ws = df.pivot(index=['workload', 'Channel', 'interface'], columns=['mitigation'], values='WS').reset_index()\n",
    "df_ws[['workload', 'Channel','interface', 'Baseline']].to_csv('../stats/SC_500M_DDR5_8000_PRAC_Baseline.csv', index=False)\n",
    "\n",
    "for mitigation in set(mitigation_list) - set(['Baseline']):\n",
    "     df_ws[mitigation] = df_ws[mitigation] / df_ws['Baseline']\n",
    "df_ws.drop(columns=['Baseline'], inplace=True)\n",
    "\n",
    "# Define benchmark suites and their corresponding workloads\n",
    "benchmark_suites = {\n",
    "    'SPEC2K6 (23)': ['401.bzip2', '403.gcc', '429.mcf', '433.milc', '434.zeusmp', '435.gromacs', '436.cactusADM', '437.leslie3d', '444.namd', '445.gobmk', '447.dealII', '450.soplex', '456.hmmer', '458.sjeng', '459.GemsFDTD', '462.libquantum', '464.h264ref', '470.lbm', '471.omnetpp', '473.astar', '481.wrf', '482.sphinx3', '483.xalancbmk'], # SPEC2K6: 23\n",
    "    'SPEC2K17 (18)': ['500.perlbench', '502.gcc', '505.mcf', '507.cactuBSSN', '508.namd', '510.parest', '511.povray', '519.lbm', '520.omnetpp', '523.xalancbmk', '525.x264', '526.blender', '531.deepsjeng', '538.imagick', '541.leela', '544.nab', '549.fotonik3d', '557.xz'], # SPEC2K17: 18\n",
    "    'TPC (4)': ['tpcc64', 'tpch17', 'tpch2', 'tpch6'], #tpc: 4\n",
    "    # TODO: Enable Hadoop and LonestartGPU after fixing the performance shooting problem + h264_decode\n",
    "    'Hadoop (3)': ['grep_map0', 'wc_8443', 'wc_map0'], #Hadoop: 3\n",
    "    'MediaBench (3)': ['h264_encode', 'jp2_decode', 'jp2_encode'], #mediabench: 3\n",
    "    'YCSB (6)': ['ycsb_abgsave', 'ycsb_aserver', 'ycsb_bserver', 'ycsb_cserver', 'ycsb_dserver', 'ycsb_eserver'] #ycsb:6\n",
    "}\n",
    "\n",
    "#\n",
    "mitigation_list = [\"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "# Function to calculate geometric mean\n",
    "def calculate_geometric_mean(series):\n",
    "    return np.prod(series) ** (1 / len(series))\n",
    "\n",
    "# Function to calculate and add geometric means as new rows\n",
    "def add_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "\n",
    "    for Channel in df['Channel'].unique():\n",
    "        for interface in df['interface'].unique():  # Loop through unique interfaces\n",
    "            for suite_name, workloads in benchmark_suites.items():\n",
    "                suite_df = df[(df['workload'].isin(workloads)) & (df['Channel'] == Channel) & (df['interface'] == interface)]\n",
    "                if not suite_df.empty:\n",
    "                    geomeans = {}\n",
    "                    \n",
    "                    # Dynamically calculate geometric means for each mitigation\n",
    "                    for mitigation in mitigation_list:\n",
    "                        if mitigation in suite_df.columns:  # Ensure the column exists\n",
    "                            geomeans[mitigation] = calculate_geometric_mean(suite_df[mitigation])\n",
    "                    \n",
    "                    # Create a new row\n",
    "                    geomean_row = {'Channel': Channel, 'interface': interface, 'workload': suite_name, **geomeans}\n",
    "                    geomean_rows.append(geomean_row)  # Append to the list\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "# Function to add combined geometric means for all workloads in each channel and interface\n",
    "def add_all_workloads_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "    \n",
    "    for Channel in df['Channel'].unique():\n",
    "        for interface in df['interface'].unique():  # Loop through unique interfaces\n",
    "            Channel_interface_df = df[(df['Channel'] == Channel) & (df['interface'] == interface)]\n",
    "            geomean_values = {}\n",
    "\n",
    "            # Calculate geometric means for each mitigation in the list\n",
    "            for mitigation in mitigation_list:\n",
    "                if mitigation in Channel_interface_df.columns:  # Ensure the column exists\n",
    "                    geomean_values[mitigation] = calculate_geometric_mean(Channel_interface_df[mitigation])\n",
    "\n",
    "            # Create a new row for the combined results\n",
    "            geomean_row = {'Channel': Channel, 'interface': interface, 'workload': 'All (57)', **geomean_values}\n",
    "            geomean_rows.append(geomean_row)  # Append to the list\n",
    "    \n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "# Call function to calculate and merge geometric means\n",
    "geomean_df = add_geomean_rows(df_ws)\n",
    "geomean_df = add_all_workloads_geomean_rows(geomean_df)\n",
    "print(geomean_df)\n",
    "geomean_df.to_csv('./../stats/SC_500M_Timing_Based_RFM_PRAC_Timing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4-Core, MOP, 500M, Open Page, Varying Channel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     workload  Channel  1RFM-1tREFI  1RFM-2tREFI  1RFM-4tREFI  2RFM-1tREFI  \\\n",
      "0        MIX0      1.0     0.880229     0.940200     0.971027     0.758118   \n",
      "1        MIX1      1.0     0.872512     0.935833     0.956798     0.755463   \n",
      "2       MIX10      1.0     0.879150     0.939839     0.970387     0.757806   \n",
      "3       MIX11      1.0     0.880567     0.934922     0.966918     0.752932   \n",
      "4       MIX12      1.0     0.898994     0.951332     0.975193     0.800485   \n",
      "..        ...      ...          ...          ...          ...          ...   \n",
      "92  LLLL (15)      1.0     0.961435     0.980751     0.990163     0.921014   \n",
      "93  HHMM (15)      1.0     0.888772     0.944122     0.971781     0.776921   \n",
      "94  HHLL (15)      1.0     0.922418     0.961600     0.980955     0.843655   \n",
      "95  MMLL (15)      1.0     0.926868     0.963279     0.980894     0.853265   \n",
      "96   All (90)      1.0     0.912891     0.956559     0.977938     0.824076   \n",
      "\n",
      "    4RFM-1tREFI  Mix_index Benchmark_Types  \n",
      "0      0.515321        0.0       HHHH (15)  \n",
      "1      0.510743        1.0       HHHH (15)  \n",
      "2      0.515485       10.0       HHHH (15)  \n",
      "3      0.508835       11.0       HHHH (15)  \n",
      "4      0.580489       12.0       HHHH (15)  \n",
      "..          ...        ...             ...  \n",
      "92     0.818261        NaN             NaN  \n",
      "93     0.544756        NaN             NaN  \n",
      "94     0.665906        NaN             NaN  \n",
      "95     0.674377        NaN             NaN  \n",
      "96     0.625078        NaN             NaN  \n",
      "\n",
      "[97 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "multi_cores_out_path = '../../prac_study/TimingChannel/4cores_results/OriginalTiming'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"mitigation\", \"workload\"])\n",
    "mitigation_list = [\"Baseline\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "for mitigation in mitigation_list:\n",
    "    result_path = multi_cores_out_path + \"/\" + mitigation +\"/stats/\"\n",
    "    result_list = [x[:-4] for x in os.listdir(result_path) if x.endswith(\".txt\")]\n",
    "    for result_filename in result_list:\n",
    "        result_file = open(result_path + result_filename + \".txt\", \"r\")\n",
    "        Channel = int(result_filename.split(\"_\")[0])\n",
    "        interface = int(result_filename.split(\"_\")[1])\n",
    "        workload = \"_\".join(result_filename.split(\"_\")[2:])\n",
    "\n",
    "        w0=''\n",
    "        w1=''\n",
    "        w2=''\n",
    "        w3=''\n",
    "        ipc_0 = 0\n",
    "        ipc_1 = 0\n",
    "        ipc_2 = 0\n",
    "        ipc_3 = 0\n",
    "        cycle_0 = 0\n",
    "        cycle_1 = 0\n",
    "        cycle_2 = 0\n",
    "        cycle_3 = 0\n",
    "        num_inst_0=0\n",
    "        num_inst_1=0\n",
    "        num_inst_2=0\n",
    "        num_inst_3=0\n",
    "        num_rd_reqs=0\n",
    "        num_wr_reqs=0\n",
    "        wr_reqs_ratio = 0.0\n",
    "        # num_tREFI_period=0\n",
    "        # num_tREFW_period=0\n",
    "        for line in result_file.readlines():\n",
    "            if (\"name_trace_0:\" in line):\n",
    "                w0 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_1:\" in line):\n",
    "                w1 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_2:\" in line):\n",
    "                w2 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_3:\" in line):\n",
    "                w3 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\" cycles_recorded_core_0:\" in line):\n",
    "                cycle_0 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_1:\" in line):\n",
    "                cycle_1 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_2:\" in line):\n",
    "                cycle_2 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_3:\" in line):\n",
    "                cycle_3 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_0\" in line):\n",
    "                num_inst_0 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_1\" in line):\n",
    "                num_inst_1 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_2\" in line):\n",
    "                num_inst_2 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_3\" in line):\n",
    "                num_inst_3 = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_read_requests\" in line):\n",
    "                num_rd_reqs = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_write_requests\" in line):\n",
    "                num_wr_reqs = int(line.split(\" \")[-1])\n",
    "            # if (\" prac_num_recovery\" in line):\n",
    "            #     num_abo = int(line.split(\" \")[-1])\n",
    "            # if (\" num_refresh_command_0\" in line):\n",
    "            #     num_tREFI_period = int(line.split(\" \")[-1])\n",
    "            # if (\" num_refresh_window_0\" in line):\n",
    "            #     num_tREFW_period = int(line.split(\" \")[-1])            \n",
    "                \n",
    "        if (cycle_0 == 0 and cycle_1 == 0 and cycle_2 == 0 and cycle_3 == 0):\n",
    "            continue\n",
    "        if (cycle_0 == 0 or cycle_1 == 0 or cycle_2 == 0 or cycle_3 == 0):\n",
    "            print(\"Error: \" + result_filename)\n",
    "        ipc_0 = int(num_inst_0) / cycle_0\n",
    "        ipc_1 = int(num_inst_1) / cycle_1\n",
    "        ipc_2 = int(num_inst_2) / cycle_2\n",
    "        ipc_3 = int(num_inst_3) / cycle_3\n",
    "        \n",
    "        wr_reqs_ratio = float(int(num_wr_reqs)/int(num_rd_reqs + num_wr_reqs))\n",
    "        result_file.close()\n",
    "        # Create a new DataFrame for the new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'mitigation': [mitigation],\n",
    "            'workload': [workload],\n",
    "            'Channel': [Channel],\n",
    "            'interface': [interface],\n",
    "            'wl0': [w0],\n",
    "            'wl1': [w1],\n",
    "            'wl2': [w2],\n",
    "            'wl3': [w3],\n",
    "            'ipc0': [ipc_0],\n",
    "            'ipc1': [ipc_1],\n",
    "            'ipc2': [ipc_2],\n",
    "            'ipc3': [ipc_3],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df_sc_ipc = pd.read_csv('../stats/SC_500M_DDR5_8000_Original_Baseline.csv')\n",
    "# Choose only interested baseline\n",
    "df_sc_ipc = df_sc_ipc[['workload', 'Channel', 'interface', 'Baseline']]\n",
    "df_sc_ipc = df_sc_ipc[(df_sc_ipc['interface'] == 8000)]\n",
    "# df_sc_ipc = df_sc_ipc.drop(columns=['interface'])\n",
    "df_sc_ipc = df_sc_ipc.rename(columns={'workload': 'workload_sc'})\n",
    "# print(df_sc_ipc)\n",
    "\n",
    "# First, merge df with df_sc_ipc for each workload (wl0, wl1, wl2, wl3)\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl0'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl0'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl1'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl1'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' again if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl2'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl2'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' again if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl3'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl3'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Final cleanup\n",
    "\n",
    "df['normalzied_ipc0'] = df['ipc0'] / df['ipc_wl0']\n",
    "df['normalzied_ipc1'] = df['ipc1'] / df['ipc_wl1']\n",
    "df['normalzied_ipc2'] = df['ipc2'] / df['ipc_wl2']\n",
    "df['normalzied_ipc3'] = df['ipc3'] / df['ipc_wl3']\n",
    "\n",
    "df['WS'] = df[['normalzied_ipc0', 'normalzied_ipc1', 'normalzied_ipc2', 'normalzied_ipc3']].sum(axis=1)\n",
    "\n",
    "df_closed_cap1_ws = df[['mitigation', 'workload', 'Channel', 'WS']]\n",
    "\n",
    "df_closed_cap1_ws_pivot = df_closed_cap1_ws.pivot(index=['workload', 'Channel'], columns=['mitigation'], values='WS').reset_index()\n",
    "for mitigation in set(mitigation_list) - set(['Baseline']):\n",
    "     df_closed_cap1_ws_pivot[mitigation] = df_closed_cap1_ws_pivot[mitigation] / df_closed_cap1_ws_pivot['Baseline']\n",
    "df_closed_cap1_ws_pivot.drop(columns=['Baseline'], inplace=True)\n",
    "##### Calculate the Geomean for each workload type\n",
    "# Define benchmark suites and their corresponding workloads ranges\n",
    "benchmark_types = {\n",
    "    'HHHH (15)': list(range(0, 15)),   # From Mix0-Mix14\n",
    "    'MMMM (15)': list(range(15, 30)),  # From Mix15-Mix29\n",
    "    'LLLL (15)': list(range(30, 45)),  # From Mix30-Mix44\n",
    "    'HHMM (15)': list(range(45, 60)),  # From Mix45-Mix59\n",
    "    'HHLL (15)': list(range(60, 75)),  # From Mix60-Mix74\n",
    "    'MMLL (15)': list(range(75, 90)),  # From Mix75-Mix89\n",
    "}\n",
    "\n",
    "# DataFrame Example (you already have your df)\n",
    "# Assuming your column of interest is 'PRAC_WO_Mitigation-ClosedCap1'\n",
    "\n",
    "# Add a new column to assign each Mix to the appropriate suite\n",
    "def assign_benchmark_types(mix_index):\n",
    "    for suite, mix_range in benchmark_types.items():\n",
    "        if mix_index in mix_range:\n",
    "            return suite\n",
    "    return None\n",
    "\n",
    "# Assuming 'workload' has values like 'MIX0', 'MIX1', etc., you can extract the index\n",
    "df_closed_cap1_ws_pivot['Mix_index'] = df_closed_cap1_ws_pivot['workload'].str.extract(r'(\\d+)').astype(int)  # Extract Mix number\n",
    "df_closed_cap1_ws_pivot['Benchmark_Types'] = df_closed_cap1_ws_pivot['Mix_index'].apply(assign_benchmark_types)  # Assign benchmark suite\n",
    "\n",
    "# Function to calculate the geometric mean\n",
    "def geom_mean(series):\n",
    "    return np.exp(np.log(series).mean())\n",
    "\n",
    "# Function to calculate and add geometric means as new rows\n",
    "def add_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "\n",
    "    for Channel in df['Channel'].unique():\n",
    "        for suite_name, mix_indices in benchmark_types.items():\n",
    "            # Create a list of corresponding workload names (e.g., MIX0, MIX1)\n",
    "            workloads = [f'MIX{i}' for i in mix_indices]\n",
    "            suite_df = df[df['workload'].isin(workloads) & (df['Channel'] == Channel)]\n",
    "            if not suite_df.empty:\n",
    "                geomeans = {}\n",
    "                \n",
    "                # Dynamically calculate geometric means for each mitigation\n",
    "                for mitigation in mitigation_list:\n",
    "                    geomeans[mitigation] = calculate_geometric_mean(suite_df[mitigation])\n",
    "                \n",
    "                # Create a new row\n",
    "                geomean_row = {'Channel': Channel, 'workload': suite_name, **geomeans}\n",
    "                geomean_rows.append(geomean_row)  # Append to the list\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "def add_all_workloads_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "    \n",
    "    for Channel in df['Channel'].unique():\n",
    "        Channel_df = df[df['Channel'] == Channel]\n",
    "        geomean_values = {}\n",
    "        \n",
    "        # Calculate geometric means for each mitigation in the list\n",
    "        for mitigation in mitigation_list:\n",
    "            if mitigation in Channel_df.columns:  # Ensure the column exists\n",
    "                geomean_values[mitigation] = calculate_geometric_mean(Channel_df[mitigation])\n",
    "\n",
    "        # Create a new row for the combined results\n",
    "        geomean_row = {'Channel': Channel, 'workload': 'All (90)', **geomean_values}\n",
    "        geomean_rows.append(geomean_row)  # Append to the list\n",
    "    \n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "mitigation_list = [\"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "\n",
    "geomean_df = add_geomean_rows(df_closed_cap1_ws_pivot)\n",
    "geomean_df = add_all_workloads_geomean_rows(geomean_df)\n",
    "print(geomean_df)\n",
    "geomean_df[['workload', 'Channel', \"Benchmark_Types\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', '2RFM-1tREFI', '4RFM-1tREFI']].to_csv('../stats/4cores_OPTMC_DDR5_8000_500M_Heterogeneous_Timing_Based_RFM_Original.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "multi_cores_out_path = '../../prac_study/TimingChannel/4cores_results/PRACTiming'\n",
    "\n",
    "df = pd.DataFrame(columns=[\"mitigation\", \"workload\"])\n",
    "mitigation_list = [\"Baseline\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', \n",
    "                   '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "for mitigation in mitigation_list:\n",
    "    result_path = multi_cores_out_path + \"/\" + mitigation +\"/stats/\"\n",
    "    result_list = [x[:-4] for x in os.listdir(result_path) if x.endswith(\".txt\")]\n",
    "    for result_filename in result_list:\n",
    "        result_file = open(result_path + result_filename + \".txt\", \"r\")\n",
    "        Channel = int(result_filename.split(\"_\")[0])\n",
    "        interface = int(result_filename.split(\"_\")[1])\n",
    "        workload = \"_\".join(result_filename.split(\"_\")[2:])\n",
    "\n",
    "        w0=''\n",
    "        w1=''\n",
    "        w2=''\n",
    "        w3=''\n",
    "        ipc_0 = 0\n",
    "        ipc_1 = 0\n",
    "        ipc_2 = 0\n",
    "        ipc_3 = 0\n",
    "        cycle_0 = 0\n",
    "        cycle_1 = 0\n",
    "        cycle_2 = 0\n",
    "        cycle_3 = 0\n",
    "        num_inst_0=0\n",
    "        num_inst_1=0\n",
    "        num_inst_2=0\n",
    "        num_inst_3=0\n",
    "        num_rd_reqs=0\n",
    "        num_wr_reqs=0\n",
    "        wr_reqs_ratio = 0.0\n",
    "        # num_tREFI_period=0\n",
    "        # num_tREFW_period=0\n",
    "        for line in result_file.readlines():\n",
    "            if (\"name_trace_0:\" in line):\n",
    "                w0 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_1:\" in line):\n",
    "                w1 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_2:\" in line):\n",
    "                w2 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\"name_trace_3:\" in line):\n",
    "                w3 = str(line.split(\"/\")[-1]).strip()\n",
    "            if (\" cycles_recorded_core_0:\" in line):\n",
    "                cycle_0 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_1:\" in line):\n",
    "                cycle_1 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_2:\" in line):\n",
    "                cycle_2 = int(line.split(\" \")[-1])\n",
    "            if (\" cycles_recorded_core_3:\" in line):\n",
    "                cycle_3 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_0\" in line):\n",
    "                num_inst_0 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_1\" in line):\n",
    "                num_inst_1 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_2\" in line):\n",
    "                num_inst_2 = int(line.split(\" \")[-1])\n",
    "            if (\" insts_recorded_core_3\" in line):\n",
    "                num_inst_3 = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_read_requests\" in line):\n",
    "                num_rd_reqs = int(line.split(\" \")[-1])\n",
    "            if (\" total_num_write_requests\" in line):\n",
    "                num_wr_reqs = int(line.split(\" \")[-1])\n",
    "            # if (\" prac_num_recovery\" in line):\n",
    "            #     num_abo = int(line.split(\" \")[-1])\n",
    "            # if (\" num_refresh_command_0\" in line):\n",
    "            #     num_tREFI_period = int(line.split(\" \")[-1])\n",
    "            # if (\" num_refresh_window_0\" in line):\n",
    "            #     num_tREFW_period = int(line.split(\" \")[-1])            \n",
    "                \n",
    "        if (cycle_0 == 0 and cycle_1 == 0 and cycle_2 == 0 and cycle_3 == 0):\n",
    "            continue\n",
    "        if (cycle_0 == 0 or cycle_1 == 0 or cycle_2 == 0 or cycle_3 == 0):\n",
    "            print(\"Error: \" + result_filename)\n",
    "        ipc_0 = int(num_inst_0) / cycle_0\n",
    "        ipc_1 = int(num_inst_1) / cycle_1\n",
    "        ipc_2 = int(num_inst_2) / cycle_2\n",
    "        ipc_3 = int(num_inst_3) / cycle_3\n",
    "        \n",
    "        wr_reqs_ratio = float(int(num_wr_reqs)/int(num_rd_reqs + num_wr_reqs))\n",
    "        result_file.close()\n",
    "        # Create a new DataFrame for the new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'mitigation': [mitigation],\n",
    "            'workload': [workload],\n",
    "            'Channel': [Channel],\n",
    "            'interface': [interface],\n",
    "            'wl0': [w0],\n",
    "            'wl1': [w1],\n",
    "            'wl2': [w2],\n",
    "            'wl3': [w3],\n",
    "            'ipc0': [ipc_0],\n",
    "            'ipc1': [ipc_1],\n",
    "            'ipc2': [ipc_2],\n",
    "            'ipc3': [ipc_3],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df_sc_ipc = pd.read_csv('../stats/SC_500M_DDR5_8000_PRAC_Baseline.csv')\n",
    "# Choose only interested baseline\n",
    "df_sc_ipc = df_sc_ipc[['workload', 'Channel', 'interface', 'Baseline']]\n",
    "df_sc_ipc = df_sc_ipc[(df_sc_ipc['interface'] == 8000)]\n",
    "# df_sc_ipc = df_sc_ipc.drop(columns=['interface'])\n",
    "df_sc_ipc = df_sc_ipc.rename(columns={'workload': 'workload_sc'})\n",
    "# print(df_sc_ipc)\n",
    "\n",
    "# First, merge df with df_sc_ipc for each workload (wl0, wl1, wl2, wl3)\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl0'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl0'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl1'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl1'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' again if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl2'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl2'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Drop 'workload' again if it exists\n",
    "\n",
    "df = df.merge(df_sc_ipc[['Channel', 'workload_sc', 'Baseline']], left_on=['Channel', 'wl3'], right_on=['Channel', 'workload_sc'], how='left').rename(columns={'Baseline': 'ipc_wl3'})\n",
    "if 'workload_sc' in df.columns:\n",
    "    df = df.drop(columns=['workload_sc'])  # Final cleanup\n",
    "\n",
    "df['normalzied_ipc0'] = df['ipc0'] / df['ipc_wl0']\n",
    "df['normalzied_ipc1'] = df['ipc1'] / df['ipc_wl1']\n",
    "df['normalzied_ipc2'] = df['ipc2'] / df['ipc_wl2']\n",
    "df['normalzied_ipc3'] = df['ipc3'] / df['ipc_wl3']\n",
    "\n",
    "df['WS'] = df[['normalzied_ipc0', 'normalzied_ipc1', 'normalzied_ipc2', 'normalzied_ipc3']].sum(axis=1)\n",
    "\n",
    "df_closed_cap1_ws = df[['mitigation', 'workload', 'Channel', 'WS']]\n",
    "\n",
    "df_closed_cap1_ws_pivot = df_closed_cap1_ws.pivot(index=['workload', 'Channel'], columns=['mitigation'], values='WS').reset_index()\n",
    "for mitigation in set(mitigation_list) - set(['Baseline']):\n",
    "     df_closed_cap1_ws_pivot[mitigation] = df_closed_cap1_ws_pivot[mitigation] / df_closed_cap1_ws_pivot['Baseline']\n",
    "df_closed_cap1_ws_pivot.drop(columns=['Baseline'], inplace=True)\n",
    "##### Calculate the Geomean for each workload type\n",
    "# Define benchmark suites and their corresponding workloads ranges\n",
    "benchmark_types = {\n",
    "    'HHHH (15)': list(range(0, 15)),   # From Mix0-Mix14\n",
    "    'MMMM (15)': list(range(15, 30)),  # From Mix15-Mix29\n",
    "    'LLLL (15)': list(range(30, 45)),  # From Mix30-Mix44\n",
    "    'HHMM (15)': list(range(45, 60)),  # From Mix45-Mix59\n",
    "    'HHLL (15)': list(range(60, 75)),  # From Mix60-Mix74\n",
    "    'MMLL (15)': list(range(75, 90)),  # From Mix75-Mix89\n",
    "}\n",
    "\n",
    "# DataFrame Example (you already have your df)\n",
    "# Assuming your column of interest is 'PRAC_WO_Mitigation-ClosedCap1'\n",
    "\n",
    "# Add a new column to assign each Mix to the appropriate suite\n",
    "def assign_benchmark_types(mix_index):\n",
    "    for suite, mix_range in benchmark_types.items():\n",
    "        if mix_index in mix_range:\n",
    "            return suite\n",
    "    return None\n",
    "\n",
    "# Assuming 'workload' has values like 'MIX0', 'MIX1', etc., you can extract the index\n",
    "df_closed_cap1_ws_pivot['Mix_index'] = df_closed_cap1_ws_pivot['workload'].str.extract(r'(\\d+)').astype(int)  # Extract Mix number\n",
    "df_closed_cap1_ws_pivot['Benchmark_Types'] = df_closed_cap1_ws_pivot['Mix_index'].apply(assign_benchmark_types)  # Assign benchmark suite\n",
    "\n",
    "# Function to calculate the geometric mean\n",
    "def geom_mean(series):\n",
    "    return np.exp(np.log(series).mean())\n",
    "\n",
    "# Function to calculate and add geometric means as new rows\n",
    "def add_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "\n",
    "    for Channel in df['Channel'].unique():\n",
    "        for suite_name, mix_indices in benchmark_types.items():\n",
    "            # Create a list of corresponding workload names (e.g., MIX0, MIX1)\n",
    "            workloads = [f'MIX{i}' for i in mix_indices]\n",
    "            suite_df = df[df['workload'].isin(workloads) & (df['Channel'] == Channel)]\n",
    "            if not suite_df.empty:\n",
    "                geomeans = {}\n",
    "                \n",
    "                # Dynamically calculate geometric means for each mitigation\n",
    "                for mitigation in mitigation_list:\n",
    "                    geomeans[mitigation] = calculate_geometric_mean(suite_df[mitigation])\n",
    "                \n",
    "                # Create a new row\n",
    "                geomean_row = {'Channel': Channel, 'workload': suite_name, **geomeans}\n",
    "                geomean_rows.append(geomean_row)  # Append to the list\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "def add_all_workloads_geomean_rows(df):\n",
    "    geomean_rows = []  # List to collect new rows\n",
    "    \n",
    "    for Channel in df['Channel'].unique():\n",
    "        Channel_df = df[df['Channel'] == Channel]\n",
    "        geomean_values = {}\n",
    "        \n",
    "        # Calculate geometric means for each mitigation in the list\n",
    "        for mitigation in mitigation_list:\n",
    "            if mitigation in Channel_df.columns:  # Ensure the column exists\n",
    "                geomean_values[mitigation] = calculate_geometric_mean(Channel_df[mitigation])\n",
    "\n",
    "        # Create a new row for the combined results\n",
    "        geomean_row = {'Channel': Channel, 'workload': 'All (90)', **geomean_values}\n",
    "        geomean_rows.append(geomean_row)  # Append to the list\n",
    "    \n",
    "    # Convert list of rows to DataFrame\n",
    "    geomean_df = pd.DataFrame(geomean_rows)\n",
    "    \n",
    "    return pd.concat([df, geomean_df], ignore_index=True)\n",
    "\n",
    "mitigation_list = [\"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', '2RFM-1tREFI', '4RFM-1tREFI']\n",
    "\n",
    "geomean_df = add_geomean_rows(df_closed_cap1_ws_pivot)\n",
    "geomean_df = add_all_workloads_geomean_rows(geomean_df)\n",
    "print(geomean_df)\n",
    "geomean_df[['workload', 'Channel', \"Benchmark_Types\", \"1RFM-4tREFI\", '1RFM-2tREFI', '1RFM-1tREFI', '2RFM-1tREFI', '4RFM-1tREFI']].to_csv('../stats/4cores_OPTMC_DDR5_8000_500M_Heterogeneous_Timing_Based_RFM_PRAC.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
